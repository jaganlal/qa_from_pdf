{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2TokenizerFast\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "\n",
    "file_name = './data/sbc-sample.pdf'\n",
    "output_file = './output/sbc-sample.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='1 of 8 Insurance Company 1: Plan Option 1  Coverage Period: 01/01/2013 – 12/31/2013 \\nSummary of Benefits and Coverage: What this Plan Covers & What it Costs  Coverage for: Individual + Spouse | Plan Type: PPO \\nQuestions:  Call 1-800-[insert] or visit us at www .[insert] . \\nIf you aren’t clear about any of the underlined terms used in this form, see the Glossary.  You can view the Glossary \\nat www.[insert]  or call 1- 800-[ insert ] to request a copy.   \\n This is  only a summary . If you want more detail about you r coverage and costs , you can get the complete terms in the policy or plan \\ndocument at www. [insert]  or by calling 1-800-[insert] . \\n  \\nImportant Questions  Answers  Why this Matters:  \\nWhat is the overa ll \\ndeductible ? $500 person  /  \\n$1,000 family  \\nDoesn’t apply to preventive  care  You must pay all the costs up to the deductible  amount before this  plan begins to pay for \\ncovered services you use. Check your policy or plan document to see when the deductible  \\nstarts over (usually, but not always, January 1st). See the chart starting on page 2 for how \\nmuch you pay for covered services after you meet the deductible . \\nAre there other  \\ndeductibles  for specific \\nservices?  Yes. $300 for prescription drug \\ncoverage .  There are no other \\nspecific deductibles . You must pay all of the costs for these services up to the specific deductible  amount \\nbefore this plan begins to pay for these services.  \\nIs there an out–of–\\npocket limit  on my \\nexpenses?  Yes. For participating provider s \\n$2,500  person / $5,000 \\nfamily  \\nFor non -participating providers \\n$4,000  person / $8,000  family  The out-of-pocket limit  is the most you could pay during a coverage period (usually one \\nyear) for your share of the cost of covered services. This limit helps you  plan for health \\ncare expenses.  \\nWhat is not included in  \\nthe out–of–pocket \\nlimit ? Premium s, balance -billed \\ncharges, and health care this \\nplan doesn’t cover.  Even though you pay these expenses, they don’t count toward the out-of-pocket limit .  \\nIs there an overall \\nannual limit on what \\nthe plan pays?  No.  The chart starting on page 2 describes any limits on what the plan will pay for specific  \\ncovered services, such as office visits.  \\nDoes this plan use a \\nnetwork  of providers ? Yes. See www. [insert] .com or \\ncall 1-800-[insert] for a list of \\nparticipating providers . If you use an in-network doctor or other health care provider , this plan will pay some or all \\nof the costs of covered services . Be aware, your in -network doctor or hospital may use an \\nout-of-network provider  for some services.  Plans  use the term in-network , preferred , or \\nparticipating  for providers  in their network .  See the chart starting on page 2 for how this \\nplan pays different kinds of providers .  \\nDo I need a referral to \\nsee a specialist ? No. You  don’t need a referral to \\nsee a specialist . You can see the specialist  you choose without permission from this plan. \\nAre there services this \\nplan doesn’t cover?  Yes. Some of the services this  plan doesn’t cover are listed  on page 4 . See your policy or plan \\ndocument for additional information about excluded services . \\nOMB Control Numbers 1545 -2229 , \\n1210 -0147 , and  0938 -1146   \\nCorrected on May 11, 2012' metadata={'source': './data/sbc-sample.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "# You MUST add your PDF to local files in this notebook (folder icon on left hand side of screen)\n",
    "\n",
    "# Simple method - Split by pages \n",
    "loader = PyPDFLoader(file_name)\n",
    "pages = loader.load_and_split()\n",
    "print(pages[0])\n",
    "\n",
    "# SKIP TO STEP 2 IF YOU'RE USING THIS METHOD\n",
    "chunks = pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Advanced method - Split by chunk\n",
    "\n",
    "# Step 1: Convert PDF to text\n",
    "import textract\n",
    "doc = textract.process(file_name)\n",
    "\n",
    "# Step 2: Save to .txt and reopen (helps prevent issues)\n",
    "with open(output_file, 'w') as f:\n",
    "    f.write(doc.decode('utf-8'))\n",
    "\n",
    "with open(output_file, 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Step 3: Create function to count tokens\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# Step 4: Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 512,\n",
    "    chunk_overlap  = 24,\n",
    "    length_function = count_tokens,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quick data visualization to ensure chunking was successful\n",
    "\n",
    "# # Create a list of token counts\n",
    "# token_counts = [count_tokens(chunk.page_content) for chunk in chunks]\n",
    "\n",
    "# # Create a DataFrame from the token counts\n",
    "# df = pd.DataFrame({'Token Count': token_counts})\n",
    "\n",
    "# # Create a histogram of the token count distribution\n",
    "# df.hist(bins=40, )\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf525f848cc34e93ac090eae70b9ebd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index import LangchainEmbedding\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "embed_model = LangchainEmbedding(embeddings)\n",
    "\n",
    "# Create vector database\n",
    "db = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check similarity search is working\n",
    "# query = 'What is the copay for Diagnostic test?'\n",
    "# docs = db.similarity_search(query)\n",
    "# docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff144debb8446a4aeb4f7fbd105d19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create QA chain to integrate similarity search with user queries (answer query from knowledge base)\n",
    "\n",
    "# 'google/flan-t5-large'\n",
    "# 'bigscience/bloom-560m' - NOT WORKING\n",
    "# 'bigscience/bloom-7b1' - NOT WORKING\n",
    "# 'MetaIX/GPT4-X-Alpaca-30B-4bit' - NOT WORKING\n",
    "# 'stanfordnlp/SteamSHP-flan-t5-large' - NOT WORKING\n",
    "# \"THUDM/chatglm-6b-int4\" - NOT WORKING\n",
    "\n",
    "# 'stanfordnlp/SteamSHP-flan-t5-large' - gives wrong answer\n",
    "\n",
    "flan_ul2 = HuggingFaceHub(repo_id='stanford-oval/paraphraser-bart-large', model_kwargs={'temperature': 0.1})\n",
    "chain = load_qa_chain(flan_ul2, chain_type=\"stuff\")\n",
    "\n",
    "query = 'what will be my deductible?'\n",
    "# query = 'what is my out of pocket limit?'\n",
    "# query = 'what is the radiology cost for having a baby'\n",
    "docs = db.similarity_search(query)\n",
    "\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display\n",
    "# import ipywidgets as widgets\n",
    "\n",
    "# # Create conversation chain that uses our vectordb as retriver, this also allows for chat history management\n",
    "# qa = ConversationalRetrievalChain.from_llm(flan_ul2, db.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_history = []\n",
    "\n",
    "# def on_submit(_):\n",
    "#     query = input_box.value\n",
    "#     input_box.value = \"\"\n",
    "    \n",
    "#     if query.lower() == 'exit':\n",
    "#         print(\"Thank you for using the State of the Union chatbot!\")\n",
    "#         return\n",
    "    \n",
    "#     result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "#     chat_history.append((query, result['answer']))\n",
    "    \n",
    "#     display(widgets.HTML(f'<b>User:</b> {query}'))\n",
    "#     display(widgets.HTML(f'<b><font color=\"blue\">Chatbot:</font></b> {result[\"answer\"]}'))\n",
    "\n",
    "# print(\"Welcome to the Transformers chatbot! Type 'exit' to stop.\")\n",
    "\n",
    "# input_box = widgets.Text(placeholder='Please enter your question:')\n",
    "# input_box.continuous_update = False\n",
    "# input_box.observe(on_submit, names='value')\n",
    "# # input_box.on_submit(on_submit)\n",
    "\n",
    "# display(input_box)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
